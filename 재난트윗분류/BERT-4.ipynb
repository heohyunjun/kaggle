{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "notebookca83a5e0a0.ipynb",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# BERT 미세 조정하기"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "id": "x9OYCD6JUFnY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-30T12:18:24.514114Z",
          "iopub.execute_input": "2022-08-30T12:18:24.514659Z",
          "iopub.status.idle": "2022-08-30T12:18:24.550858Z",
          "shell.execute_reply.started": "2022-08-30T12:18:24.514554Z",
          "shell.execute_reply": "2022-08-30T12:18:24.549965Z"
        },
        "trusted": true,
        "id": "DZ-odVEgUFne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-30T12:18:24.765808Z",
          "iopub.execute_input": "2022-08-30T12:18:24.766671Z",
          "iopub.status.idle": "2022-08-30T12:18:38.288522Z",
          "shell.execute_reply.started": "2022-08-30T12:18:24.766608Z",
          "shell.execute_reply": "2022-08-30T12:18:38.286727Z"
        },
        "trusted": true,
        "id": "LwqXh92nUFng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import time\n",
        "import logging\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler,TensorDataset\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from transformers import *"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-30T12:18:38.292785Z",
          "iopub.execute_input": "2022-08-30T12:18:38.293213Z",
          "iopub.status.idle": "2022-08-30T12:18:56.637091Z",
          "shell.execute_reply.started": "2022-08-30T12:18:38.293174Z",
          "shell.execute_reply": "2022-08-30T12:18:56.635747Z"
        },
        "trusted": true,
        "id": "DNIoenoOUFnh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 시드 고정해두기\n",
        "\n",
        "def seed_everything(seed=42):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "seed_everything()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-30T12:18:56.638659Z",
          "iopub.execute_input": "2022-08-30T12:18:56.640510Z",
          "iopub.status.idle": "2022-08-30T12:18:56.652474Z",
          "shell.execute_reply.started": "2022-08-30T12:18:56.640457Z",
          "shell.execute_reply": "2022-08-30T12:18:56.651037Z"
        },
        "trusted": true,
        "id": "y_CJS78iUFni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset load\n",
        "train = pd.read_csv('../input/nlp-getting-started/train.csv')\n",
        "test = pd.read_csv('../input/nlp-getting-started/test.csv')\n",
        "submit = pd.read_csv('../input/nlp-getting-started/sample_submission.csv')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-30T12:18:56.655820Z",
          "iopub.execute_input": "2022-08-30T12:18:56.656251Z",
          "iopub.status.idle": "2022-08-30T12:18:56.750549Z",
          "shell.execute_reply.started": "2022-08-30T12:18:56.656216Z",
          "shell.execute_reply": "2022-08-30T12:18:56.749548Z"
        },
        "trusted": true,
        "id": "oAzirgyKUFnk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train.shape)\n",
        "train.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-30T12:18:56.752001Z",
          "iopub.execute_input": "2022-08-30T12:18:56.753297Z",
          "iopub.status.idle": "2022-08-30T12:18:56.776904Z",
          "shell.execute_reply.started": "2022-08-30T12:18:56.753254Z",
          "shell.execute_reply": "2022-08-30T12:18:56.775922Z"
        },
        "trusted": true,
        "id": "UCqoreB1UFnk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.target.value_counts()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-30T12:18:56.778270Z",
          "iopub.execute_input": "2022-08-30T12:18:56.779653Z",
          "iopub.status.idle": "2022-08-30T12:18:56.795343Z",
          "shell.execute_reply.started": "2022-08-30T12:18:56.779605Z",
          "shell.execute_reply": "2022-08-30T12:18:56.794082Z"
        },
        "trusted": true,
        "id": "EQsAZKEsUFnl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 토큰화"
      ],
      "metadata": {
        "id": "DsDXoBNIUFnm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class InputExample(object):\n",
        "    def __init__(self, id, text, label=None):\n",
        "        self.id = id\n",
        "        self.text =text\n",
        "        self.label =label\n",
        "\n",
        "class InputFeatures(object):\n",
        "    def __init__(self,\n",
        "                 example_id,\n",
        "                 choices_features,\n",
        "                 label\n",
        "\n",
        "                 ):\n",
        "        self.example_id = example_id\n",
        "        _, input_ids, input_mask, segment_ids = choices_features[0]\n",
        "        self.choices_features = {\n",
        "            'input_ids': input_ids,\n",
        "            'input_mask': input_mask,\n",
        "            'segment_ids': segment_ids\n",
        "        }\n",
        "        self.label = label"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-30T12:20:40.446822Z",
          "iopub.execute_input": "2022-08-30T12:20:40.448066Z",
          "iopub.status.idle": "2022-08-30T12:20:40.456891Z",
          "shell.execute_reply.started": "2022-08-30T12:20:40.448012Z",
          "shell.execute_reply": "2022-08-30T12:20:40.455067Z"
        },
        "trusted": true,
        "id": "KYdax0ntUFnn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# target의 id, text, target 받은 InputExample객체 저장\n",
        "def read_examples(df, is_training):\n",
        "    if not is_training:\n",
        "        df['target'] = np.zeros(len(df), dtype=np.int64)\n",
        "    examples=[]\n",
        "    for val in df[['id', 'text', 'target']].values:\n",
        "        examples.append(InputExample(id=val[0], text=val[1], label=val[2]))\n",
        "    return examples, df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-30T12:20:42.460004Z",
          "iopub.execute_input": "2022-08-30T12:20:42.460492Z",
          "iopub.status.idle": "2022-08-30T12:20:42.468986Z",
          "shell.execute_reply.started": "2022-08-30T12:20:42.460455Z",
          "shell.execute_reply": "2022-08-30T12:20:42.467343Z"
        },
        "trusted": true,
        "id": "GgI5dPlDUFnn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _truncate_seq_pair(tokens_a, tokens_b, max_length):\n",
        "    while True:\n",
        "        total_length = len(tokens_a) + len(tokens_b)\n",
        "        if total_length <= max_length:\n",
        "            break\n",
        "        if len(tokens_a) > len(tokens_b):\n",
        "            tokens_a.pop()\n",
        "        else:\n",
        "            tokens_b.pop"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-30T12:20:42.572333Z",
          "iopub.execute_input": "2022-08-30T12:20:42.574025Z",
          "iopub.status.idle": "2022-08-30T12:20:42.582176Z",
          "shell.execute_reply.started": "2022-08-30T12:20:42.573957Z",
          "shell.execute_reply": "2022-08-30T12:20:42.580363Z"
        },
        "trusted": true,
        "id": "o8QJJwfxUFno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_examples_to_features(examples, tokenizer, max_seq_length,\n",
        "                                 is_training):\n",
        "    features = []\n",
        "    for example_index, example in enumerate(examples):\n",
        "\n",
        "        text = tokenizer.tokenize(example.text)\n",
        "        MAX_TEXT_LEN = max_seq_length - 2 \n",
        "        text = text[:MAX_TEXT_LEN]\n",
        "\n",
        "        choices_features = []\n",
        "\n",
        "        tokens = [\"[CLS]\"] + text + [\"[SEP]\"]  \n",
        "        segment_ids = [0] * (len(text) + 2) \n",
        "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "        input_mask = [1] * len(input_ids)\n",
        "\n",
        "        padding_length = max_seq_length - len(input_ids)\n",
        "        input_ids += ([0] * padding_length)\n",
        "        input_mask += ([0] * padding_length)\n",
        "        segment_ids += ([0] * padding_length)\n",
        "        choices_features.append((tokens, input_ids, input_mask, segment_ids))\n",
        "        label = example.label\n",
        "        if example_index < 1 and is_training:\n",
        "            print(\"*** Example ***\")\n",
        "            print(\"idx: {}\".format(example_index))\n",
        "            print(\"id: {}\".format(example.id))\n",
        "            print(\"tokens: {}\".format(' '.join(tokens).replace('\\u2581', '_')))\n",
        "            print(\"input_ids: {}\".format(' '.join(map(str, input_ids))))\n",
        "            print(\"input_mask: {}\".format(len(input_mask)))\n",
        "            print(\"segment_ids: {}\".format(len(segment_ids)))\n",
        "            print(\"label: {}\".format(label))\n",
        "            \n",
        "        features.append(\n",
        "            InputFeatures(\n",
        "                example_id=example.id,\n",
        "                choices_features=choices_features,\n",
        "                label=label\n",
        "            )\n",
        "        )\n",
        "    return features"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-30T12:20:42.780763Z",
          "iopub.execute_input": "2022-08-30T12:20:42.782274Z",
          "iopub.status.idle": "2022-08-30T12:20:42.796241Z",
          "shell.execute_reply.started": "2022-08-30T12:20:42.782203Z",
          "shell.execute_reply": "2022-08-30T12:20:42.794656Z"
        },
        "trusted": true,
        "id": "ZiYz1JQFUFnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def select_field(features, field):\n",
        "    return [feature.choices_features[field] for feature in features]\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-30T12:20:43.151499Z",
          "iopub.execute_input": "2022-08-30T12:20:43.151965Z",
          "iopub.status.idle": "2022-08-30T12:20:43.158790Z",
          "shell.execute_reply.started": "2022-08-30T12:20:43.151913Z",
          "shell.execute_reply": "2022-08-30T12:20:43.157039Z"
        },
        "trusted": true,
        "id": "WoFMUhAdUFnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def metric(y_true, y_pred):\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred, average='macro')\n",
        "    return acc, f1"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-30T12:20:43.436544Z",
          "iopub.execute_input": "2022-08-30T12:20:43.437493Z",
          "iopub.status.idle": "2022-08-30T12:20:43.444738Z",
          "shell.execute_reply.started": "2022-08-30T12:20:43.437434Z",
          "shell.execute_reply": "2022-08-30T12:20:43.443394Z"
        },
        "trusted": true,
        "id": "A7N-2nzKUFnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 파라미터\n",
        "max_seq_length = 512  \n",
        "learning_rate = 1e-5  \n",
        "num_epochs = 2\n",
        "batch_size = 8  \n",
        "patience = 2  \n",
        "file_name = 'model'  "
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-30T13:06:16.830888Z",
          "iopub.execute_input": "2022-08-30T13:06:16.831353Z",
          "iopub.status.idle": "2022-08-30T13:06:16.837505Z",
          "shell.execute_reply.started": "2022-08-30T13:06:16.831320Z",
          "shell.execute_reply": "2022-08-30T13:06:16.836113Z"
        },
        "trusted": true,
        "id": "DtTckNWYUFnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-30T12:20:44.246654Z",
          "iopub.execute_input": "2022-08-30T12:20:44.247097Z",
          "iopub.status.idle": "2022-08-30T12:20:45.996138Z",
          "shell.execute_reply.started": "2022-08-30T12:20:44.247062Z",
          "shell.execute_reply": "2022-08-30T12:20:45.994765Z"
        },
        "trusted": true,
        "id": "ZFitypjTUFnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-30T12:20:45.998347Z",
          "iopub.execute_input": "2022-08-30T12:20:45.998697Z",
          "iopub.status.idle": "2022-08-30T12:20:46.009281Z",
          "shell.execute_reply.started": "2022-08-30T12:20:45.998666Z",
          "shell.execute_reply": "2022-08-30T12:20:46.006540Z"
        },
        "trusted": true,
        "id": "arlVDulNUFnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_examples, train_df = read_examples(train, is_training=True)\n",
        "labels = train_df['target'].astype(int).values\n",
        "train_features = convert_examples_to_features(\n",
        "    train_examples, tokenizer, max_seq_length, True)\n",
        "all_input_ids = np.array(select_field(train_features, 'input_ids'))\n",
        "all_input_mask = np.array(select_field(train_features, 'input_mask'))\n",
        "all_segment_ids = np.array(select_field(train_features, 'segment_ids'))\n",
        "all_label = np.array([f.label for f in train_features])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-30T12:58:07.190785Z",
          "iopub.execute_input": "2022-08-30T12:58:07.191228Z",
          "iopub.status.idle": "2022-08-30T12:58:13.946237Z",
          "shell.execute_reply.started": "2022-08-30T12:58:07.191195Z",
          "shell.execute_reply": "2022-08-30T12:58:13.944620Z"
        },
        "trusted": true,
        "id": "NtFsB10hUFnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_examples, train_df = read_examples(train, is_training=True)\n",
        "train_examples"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-30T12:20:46.011141Z",
          "iopub.execute_input": "2022-08-30T12:20:46.012356Z",
          "iopub.status.idle": "2022-08-30T12:20:46.067362Z",
          "shell.execute_reply.started": "2022-08-30T12:20:46.012308Z",
          "shell.execute_reply": "2022-08-30T12:20:46.066328Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true,
        "id": "dKbsncl9UFns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-30T12:19:00.125875Z",
          "iopub.execute_input": "2022-08-30T12:19:00.126297Z",
          "iopub.status.idle": "2022-08-30T12:19:00.148233Z",
          "shell.execute_reply.started": "2022-08-30T12:19:00.126265Z",
          "shell.execute_reply": "2022-08-30T12:19:00.146611Z"
        },
        "trusted": true,
        "id": "Hu1y81TmUFns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lables = train_df['target'].astype(int).values"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-30T12:20:50.853061Z",
          "iopub.execute_input": "2022-08-30T12:20:50.853475Z",
          "iopub.status.idle": "2022-08-30T12:20:50.860373Z",
          "shell.execute_reply.started": "2022-08-30T12:20:50.853443Z",
          "shell.execute_reply": "2022-08-30T12:20:50.859007Z"
        },
        "trusted": true,
        "id": "UUbkh91TUFnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_features = convert_examples_to_features(\n",
        "    train_examples, tokenizer, max_seq_length, True)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-30T12:20:52.490741Z",
          "iopub.execute_input": "2022-08-30T12:20:52.491918Z",
          "iopub.status.idle": "2022-08-30T12:20:58.224517Z",
          "shell.execute_reply.started": "2022-08-30T12:20:52.491873Z",
          "shell.execute_reply": "2022-08-30T12:20:58.223083Z"
        },
        "trusted": true,
        "id": "riPT2DruUFnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_examples, test_df = read_examples(test, is_training=False)\n",
        "test_features = convert_examples_to_features(\n",
        "    test_examples, tokenizer, max_seq_length, True)\n",
        "test_input_ids = torch.tensor(select_field(test_features, 'input_ids'), dtype=torch.long)\n",
        "test_input_mask = torch.tensor(select_field(test_features, 'input_mask'), dtype=torch.long)\n",
        "test_segment_ids = torch.tensor(select_field(test_features, 'segment_ids'), dtype=torch.long)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-30T12:23:41.185768Z",
          "iopub.execute_input": "2022-08-30T12:23:41.186300Z",
          "iopub.status.idle": "2022-08-30T12:23:44.570491Z",
          "shell.execute_reply.started": "2022-08-30T12:23:41.186260Z",
          "shell.execute_reply": "2022-08-30T12:23:44.569273Z"
        },
        "trusted": true,
        "id": "0gaUokoLUFnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, hidden_size=768, num_class=2):\n",
        "        super(NeuralNet, self).__init__()\n",
        "\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased',  \n",
        "                                        output_hidden_states=True,\n",
        "                                        output_attentions=True)\n",
        "        for param in self.bert.parameters():\n",
        "            param.requires_grad = True\n",
        "        self.weights = nn.Parameter(torch.rand(13, 1))\n",
        "        self.dropouts = nn.ModuleList([\n",
        "            nn.Dropout(0.5) for _ in range(5)\n",
        "        ])\n",
        "        self.fc = nn.Linear(hidden_size, num_class)\n",
        "\n",
        "    def forward(self, input_ids, input_mask, segment_ids):\n",
        "        all_hidden_states, all_attentions = self.bert(input_ids, token_type_ids=segment_ids,\n",
        "                                                                attention_mask=input_mask)[-2:]\n",
        "        batch_size = input_ids.shape[0]\n",
        "        ht_cls = torch.cat(all_hidden_states)[:, :1, :].view(\n",
        "            13, batch_size, 1, 768)\n",
        "        atten = torch.sum(ht_cls * self.weights.view(\n",
        "            13, 1, 1, 1), dim=[1, 3])\n",
        "        atten = F.softmax(atten.view(-1), dim=0)\n",
        "        feature = torch.sum(ht_cls * atten.view(13, 1, 1, 1), dim=[0, 2])\n",
        "        for i, dropout in enumerate(self.dropouts):\n",
        "            if i == 0:\n",
        "                h = self.fc(dropout(feature))\n",
        "            else:\n",
        "                h += self.fc(dropout(feature))\n",
        "        h = h / len(self.dropouts)\n",
        "        return h"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-30T12:48:49.789787Z",
          "iopub.execute_input": "2022-08-30T12:48:49.790330Z",
          "iopub.status.idle": "2022-08-30T12:48:49.806829Z",
          "shell.execute_reply.started": "2022-08-30T12:48:49.790293Z",
          "shell.execute_reply": "2022-08-30T12:48:49.805224Z"
        },
        "trusted": true,
        "id": "kW-5GYcYUFnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skf = StratifiedKFold(n_splits=7, shuffle=True, random_state=42)\n",
        "# off: out-of-fold\n",
        "oof_train = np.zeros((len(train_df), 2), dtype=np.float32)\n",
        "oof_test = np.zeros((len(test_df), 2), dtype=np.float32)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-30T12:50:11.058031Z",
          "iopub.execute_input": "2022-08-30T12:50:11.059359Z",
          "iopub.status.idle": "2022-08-30T12:50:11.065809Z",
          "shell.execute_reply.started": "2022-08-30T12:50:11.059298Z",
          "shell.execute_reply": "2022-08-30T12:50:11.064913Z"
        },
        "trusted": true,
        "id": "2CRQ9YRmUFnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skf"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-30T12:50:51.998713Z",
          "iopub.execute_input": "2022-08-30T12:50:51.999167Z",
          "iopub.status.idle": "2022-08-30T12:50:52.006845Z",
          "shell.execute_reply.started": "2022-08-30T12:50:51.999133Z",
          "shell.execute_reply": "2022-08-30T12:50:52.005636Z"
        },
        "trusted": true,
        "id": "B5R2P5zkUFnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skf.split?"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-30T12:52:51.361616Z",
          "iopub.execute_input": "2022-08-30T12:52:51.362138Z",
          "iopub.status.idle": "2022-08-30T12:52:51.429314Z",
          "shell.execute_reply.started": "2022-08-30T12:52:51.362101Z",
          "shell.execute_reply": "2022-08-30T12:52:51.427936Z"
        },
        "trusted": true,
        "id": "aGEZ3SvKUFnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_input_ids[2]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-30T12:58:41.679387Z",
          "iopub.execute_input": "2022-08-30T12:58:41.679777Z",
          "iopub.status.idle": "2022-08-30T12:58:41.689087Z",
          "shell.execute_reply.started": "2022-08-30T12:58:41.679748Z",
          "shell.execute_reply": "2022-08-30T12:58:41.687968Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true,
        "id": "F5wVcUkVUFnv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "round(4.4434,3)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-30T13:02:55.574122Z",
          "iopub.execute_input": "2022-08-30T13:02:55.574581Z",
          "iopub.status.idle": "2022-08-30T13:02:55.583442Z",
          "shell.execute_reply.started": "2022-08-30T13:02:55.574548Z",
          "shell.execute_reply": "2022-08-30T13:02:55.581776Z"
        },
        "trusted": true,
        "id": "vFK-ZG7LUFnv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for fold, (train_index, valid_index) in enumerate(skf.split(all_label, all_label)):\n",
        "    \n",
        "    # remove this line if you want to train for all 7 folds\n",
        "    if fold == 2:\n",
        "        break # due to kernel time limit\n",
        "\n",
        "    print(f'================     fold {fold}        ===============')\n",
        "\n",
        "    train_input_ids = torch.tensor(all_input_ids[train_index], dtype=torch.long)\n",
        "    train_input_mask = torch.tensor(all_input_mask[train_index], dtype=torch.long)\n",
        "    train_segment_ids = torch.tensor(all_segment_ids[train_index], dtype=torch.long)\n",
        "    train_label = torch.tensor(all_label[train_index], dtype=torch.long)\n",
        "\n",
        "    valid_input_ids = torch.tensor(all_input_ids[valid_index], dtype=torch.long)\n",
        "    valid_input_mask = torch.tensor(all_input_mask[valid_index], dtype=torch.long)\n",
        "    valid_segment_ids = torch.tensor(all_segment_ids[valid_index], dtype=torch.long)\n",
        "    valid_label = torch.tensor(all_label[valid_index], dtype=torch.long)\n",
        "\n",
        "    train = torch.utils.data.TensorDataset(train_input_ids, train_input_mask, train_segment_ids, train_label)\n",
        "    valid = torch.utils.data.TensorDataset(valid_input_ids, valid_input_mask, valid_segment_ids, valid_label)\n",
        "    test = torch.utils.data.TensorDataset(test_input_ids, test_input_mask, test_segment_ids)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
        "    valid_loader = torch.utils.data.DataLoader(valid, batch_size=batch_size, shuffle=False)\n",
        "    test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    model = NeuralNet()\n",
        "#     model.cuda()\n",
        "    loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    param_optimizer = list(model.named_parameters())\n",
        "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
        "    optimizer_grouped_parameters = [\n",
        "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}]\n",
        "\n",
        "    optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate, eps=1e-6)\n",
        "    model.train()\n",
        "\n",
        "    best_f1 = 0.\n",
        "    valid_best = np.zeros((valid_label.size(0), 2))\n",
        "\n",
        "    early_stop = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss = 0.\n",
        "        for batch in tqdm(train_loader):\n",
        "            batch = tuple(t for t in batch)\n",
        "            x_ids, x_mask, x_sids, y_truth = batch\n",
        "            y_pred = model(x_ids, x_mask, x_sids)\n",
        "            loss = loss_fn(y_pred, y_truth)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item() / len(train_loader)\n",
        "    \n",
        "        model.eval()\n",
        "        val_loss = 0.\n",
        "        valid_preds_fold = np.zeros((valid_label.size(0), 2))\n",
        "        with torch.no_grad():\n",
        "            for i, batch in tqdm(enumerate(valid_loader)):\n",
        "                batch = tuple(t.cuda() for t in batch)\n",
        "                x_ids, x_mask, x_sids, y_truth = batch\n",
        "                y_pred = model(x_ids, x_mask, x_sids).detach()\n",
        "                val_loss += loss_fn(y_pred, y_truth).item() / len(valid_loader)\n",
        "                valid_preds_fold[i * batch_size:(i + 1) * batch_size] = F.softmax(y_pred, dim=1).cpu().numpy()\n",
        "    \n",
        "        acc, f1 = metric(all_label[valid_index], np.argmax(valid_preds_fold, axis=1))\n",
        "        if best_f1 < f1:\n",
        "            early_stop = 0\n",
        "            best_f1 = f1\n",
        "            valid_best = valid_preds_fold\n",
        "            torch.save(model.state_dict(), 'model_fold_{}.bin'.format(fold))\n",
        "        else:\n",
        "            early_stop += 1\n",
        "        print(f\"epoch: {epoch}, train loss: {round(train_loss,3)}, valid loss:{round(val_loss,3)}\\\n",
        "        acc: {acc}, f1: {f1}, best_f1: {best_f1}\")\n",
        "\n",
        "        torch.cuda.empty_cache()  \n",
        "    \n",
        "        if early_stop >= patience:\n",
        "            break\n",
        "\n",
        "    test_preds_fold = np.zeros((len(test_df), 2))\n",
        "    valid_preds_fold = np.zeros((valid_label.size(0), 2))\n",
        "    model.load_state_dict(torch.load('model_fold_{}.bin'.format(fold)))\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for i, batch in tqdm(enumerate(valid_loader)):\n",
        "            batch = tuple(t.cuda() for t in batch)\n",
        "            x_ids, x_mask, x_sids, y_truth = batch\n",
        "            y_pred = model(x_ids, x_mask, x_sids).detach()\n",
        "            valid_preds_fold[i * batch_size:(i + 1) * batch_size] = F.softmax(y_pred, dim=1).cpu().numpy()\n",
        "    with torch.no_grad():\n",
        "        for i, batch in tqdm(enumerate(test_loader)):\n",
        "            batch = tuple(t.cuda() for t in batch)\n",
        "            x_ids, x_mask, x_sids = batch\n",
        "            y_pred = model(x_ids, x_mask, x_sids).detach()\n",
        "            test_preds_fold[i * batch_size:(i + 1) * batch_size] = F.softmax(y_pred, dim=1).cpu().numpy()\n",
        "    valid_best = valid_preds_fold\n",
        "    oof_train[valid_index] = valid_best\n",
        "    acc, f1 = metric(all_label[valid_index], np.argmax(valid_best, axis=1))\n",
        "    print('epoch: best, acc: {acc}, f1: {f1}, best_f1: {best_f1}')\n",
        "                \n",
        "    \n",
        "\n",
        "    oof_test += test_preds_fold / 2 # comment this line when training for 7 folds"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-30T13:07:26.181458Z",
          "iopub.execute_input": "2022-08-30T13:07:26.181883Z",
          "iopub.status.idle": "2022-08-30T19:34:39.088983Z",
          "shell.execute_reply.started": "2022-08-30T13:07:26.181850Z",
          "shell.execute_reply": "2022-08-30T19:34:39.085140Z"
        },
        "trusted": true,
        "id": "adWi66K9UFnv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5ddDe3BPUFnw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}